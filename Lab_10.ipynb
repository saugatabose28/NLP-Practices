{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7Lc9I6taO3k"
   },
   "source": [
    "# Lab 10\n",
    "\n",
    "Today, we'll explore a vector database - Pinecone. It is based on [two tutorials](https://docs.pinecone.io/examples/notebooks) from the Pinecone developers.\n",
    "\n",
    "## Setup\n",
    "\n",
    "If you haven't already, set up accounts with Pinecone and OpenAI:\n",
    "\n",
    "Pinecone - https://app.pinecone.io\n",
    "\n",
    "Once you create an account they will ask you a few questions to get it set up. Choose Python as the language. The rest you can answer however you like.\n",
    "\n",
    "OpenAI API - https://platform.openai.com/overview\n",
    "\n",
    "Note, if you are creating a new account you should get some free credits that you can use. If you already have an account, the cost for the lab should be very small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "bifSiBjLSKFK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# api key from app.pinecone.io\n",
    "    ## following lines are commented due to upload purpose in github\n",
    "    ##pinecone_api_key = ''\n",
    "\n",
    "    # api key from platform.openai.com\n",
    "    ##openai_api_key = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgyCsGklSKNV"
   },
   "source": [
    "Now, let's install the libraries we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "q03L1BYEZQfe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow==11.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyarrow==11.0.0) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow==11.0.0\n",
    "!pip install -qU \\\n",
    "  openai==0.27.7 \\\n",
    "  pinecone-client==3.1.0 \\\n",
    "  pinecone-datasets==0.7.0 \\\n",
    "  sentence-transformers==2.2.2 \\\n",
    "  tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrSfFiIC5roI"
   },
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kujS_e8s55oJ"
   },
   "source": [
    "In this notebook we will use a pre-processed dataset from Pinecone Datasets.\n",
    "\n",
    "If you are curious about what pre-processing they did. see [this notebook](https://github.com/pinecone-io/examples/blob/master/learn/search/semantic-search/semantic-search.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "lOgjRG52Zqqz",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>sparse_values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240000</th>\n",
       "      <td>515997</td>\n",
       "      <td>[-0.00531694, 0.06937869, -0.0092854, 0.003286...</td>\n",
       "      <td>{'indices': [845, 1657, 13677, 20780, 27058, 2...</td>\n",
       "      <td>{'text': ' Why is a \"law of sciences\" importan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240001</th>\n",
       "      <td>515998</td>\n",
       "      <td>[-0.09243751, 0.065432355, -0.06946959, 0.0669...</td>\n",
       "      <td>{'indices': [2110, 6324, 9754, 13677, 15207, 2...</td>\n",
       "      <td>{'text': ' Is it possible to format a BitLocke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240002</th>\n",
       "      <td>515999</td>\n",
       "      <td>[-0.021924071, 0.032280188, -0.020190848, 0.07...</td>\n",
       "      <td>{'indices': [2110, 4949, 23579, 23758, 27058, ...</td>\n",
       "      <td>{'text': ' Can formatting a hard drive stress ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240003</th>\n",
       "      <td>516000</td>\n",
       "      <td>[-0.120020054, 0.024080949, 0.10693012, -0.018...</td>\n",
       "      <td>{'indices': [22014, 24734, 24773, 25791, 25991...</td>\n",
       "      <td>{'text': ' Are the new Samsung Galaxy J7 and J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240004</th>\n",
       "      <td>516001</td>\n",
       "      <td>[-0.095293395, -0.048446465, -0.017618902, -0....</td>\n",
       "      <td>{'indices': [307, 2110, 5785, 12969, 12971, 13...</td>\n",
       "      <td>{'text': ' I just watched an add for Indonesia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                             values  \\\n",
       "240000  515997  [-0.00531694, 0.06937869, -0.0092854, 0.003286...   \n",
       "240001  515998  [-0.09243751, 0.065432355, -0.06946959, 0.0669...   \n",
       "240002  515999  [-0.021924071, 0.032280188, -0.020190848, 0.07...   \n",
       "240003  516000  [-0.120020054, 0.024080949, 0.10693012, -0.018...   \n",
       "240004  516001  [-0.095293395, -0.048446465, -0.017618902, -0....   \n",
       "\n",
       "                                            sparse_values  \\\n",
       "240000  {'indices': [845, 1657, 13677, 20780, 27058, 2...   \n",
       "240001  {'indices': [2110, 6324, 9754, 13677, 15207, 2...   \n",
       "240002  {'indices': [2110, 4949, 23579, 23758, 27058, ...   \n",
       "240003  {'indices': [22014, 24734, 24773, 25791, 25991...   \n",
       "240004  {'indices': [307, 2110, 5785, 12969, 12971, 13...   \n",
       "\n",
       "                                                 metadata  \n",
       "240000  {'text': ' Why is a \"law of sciences\" importan...  \n",
       "240001  {'text': ' Is it possible to format a BitLocke...  \n",
       "240002  {'text': ' Can formatting a hard drive stress ...  \n",
       "240003  {'text': ' Are the new Samsung Galaxy J7 and J...  \n",
       "240004  {'text': ' I just watched an add for Indonesia...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('quora_all-MiniLM-L6-bm25')\n",
    "\n",
    "# we drop metadata as will use blob column\n",
    "dataset.documents.drop(['metadata'], axis=1, inplace=True)\n",
    "dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
    "\n",
    "# we will use 80K rows of the dataset between rows 240K -> 320K\n",
    "dataset.documents.drop(dataset.documents.index[320_000:], inplace=True)\n",
    "dataset.documents.drop(dataset.documents.index[:240_000], inplace=True)\n",
    "\n",
    "# Print out a sample from the dataset to show what we are working with\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "conuh2Uo-mwR",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebd7XSamfMsC"
   },
   "source": [
    "## Creating an Index\n",
    "\n",
    "Now the data is ready, we can set up our index to store it.\n",
    "\n",
    "We begin by initializing our connection to Pinecone. This is where your API key is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "mc66NEBAcQHY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xknsDRh15-by"
   },
   "source": [
    "Now we set up our index specification. This allows us to define the cloud provider and region where we want to deploy our index. You can find a list of all available providers and regions [here](https://docs.pinecone.io/docs/projects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "m0BUsx0E590t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdaTip6CfllN"
   },
   "source": [
    "Now we create a new index called `semantic-search-fast`. It's important that we align the index `dimension` and `metric` parameters with those required by the `MiniLM-L6` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "kT8pfoO46Iwg",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 80000}},\n",
       " 'total_vector_count': 80000}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'semantic-search-fast'\n",
    "\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=384,  # dimensionality of minilm\n",
    "        metric='dotproduct',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUd1VGg6i108"
   },
   "source": [
    "Upsert the data to put it in the database (this can take 2-5 minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "RhR6WOi1huXZ",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b862cc6d5647f0aabba7a11cbf7356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PineconeApiException",
     "evalue": "(429)\nReason: Too Many Requests\nHTTP response headers: HTTPHeaderDict({'Date': 'Wed, 08 May 2024 09:25:05 GMT', 'Content-Type': 'application/json', 'Content-Length': '166', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '185', 'x-pinecone-request-id': '5373872686220939990', 'x-envoy-upstream-service-time': '68', 'server': 'envoy'})\nHTTP response body: {\"code\":8,\"message\":\"Request failed. You've reached your write unit limit for the current month (2000000). To continue writing data, upgrade your plan.\",\"details\":[]}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPineconeApiException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_105/223627333.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/utils/error_handling.py\u001b[0m in \u001b[0;36minner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/data/index.py\u001b[0m in \u001b[0;36mupsert\u001b[0;34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsert_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/data/index.py\u001b[0m in \u001b[0;36m_upsert_batch\u001b[0;34m(self, vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mvec_builder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVectorFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         return self._vector_api.upsert(\n\u001b[0m\u001b[1;32m    193\u001b[0m             UpsertRequest(\n\u001b[1;32m    194\u001b[0m                 \u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_builder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \"\"\"\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api/data_plane_api.py\u001b[0m in \u001b[0;36m__upsert\u001b[0;34m(self, upsert_request, **kwargs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'upsert_request'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0mupsert_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         self.upsert = _Endpoint(\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mcall_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'header'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content-Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         return self.api_client.call_api(\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'endpoint_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'http_method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             return self.__call_api(resource_path, method,\n\u001b[0m\u001b[1;32m    410\u001b[0m                                    \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                                    \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPineconeApiException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# perform request and return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             response_data = self.request(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mpost_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    453\u001b[0m                                             body=body)\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             return self.rest_client.POST(url,\n\u001b[0m\u001b[1;32m    456\u001b[0m                                          \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                                          \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/rest.py\u001b[0m in \u001b[0;36mPOST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m     def POST(self, url, headers=None, query_params=None, post_params=None,\n\u001b[1;32m    301\u001b[0m              body=None, _preload_content=True, _request_timeout=None):\n\u001b[0;32m--> 302\u001b[0;31m         return self.request(\"POST\", url,\n\u001b[0m\u001b[1;32m    303\u001b[0m                             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mServiceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPineconeApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPineconeApiException\u001b[0m: (429)\nReason: Too Many Requests\nHTTP response headers: HTTPHeaderDict({'Date': 'Wed, 08 May 2024 09:25:05 GMT', 'Content-Type': 'application/json', 'Content-Length': '166', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '185', 'x-pinecone-request-id': '5373872686220939990', 'x-envoy-upstream-service-time': '68', 'server': 'envoy'})\nHTTP response body: {\"code\":8,\"message\":\"Request failed. You've reached your write unit limit for the current month (2000000). To continue writing data, upgrade your plan.\",\"details\":[]}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for batch in tqdm(dataset.iter_documents(batch_size=500), total=160):\n",
    "    index.upsert(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrK_IN079Vuu"
   },
   "source": [
    "## Making Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rr4unPAq9alb"
   },
   "source": [
    "Now that our index is populated we can begin making queries. We are performing a semantic search for *similar questions*, so we should embed and search with another question.\n",
    "\n",
    "Note that we use the same model as the one used above. That's critical - otherwise the vector spaces will not be meaningfully comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Fqo_hMRZiubM",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MP2-unZ--XJ9"
   },
   "source": [
    "Now let's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "JWcO7jAK-N_1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '69331',\n",
       "              'metadata': {'text': \" What's the world's largest city?\"},\n",
       "              'score': 0.785655141,\n",
       "              'values': []},\n",
       "             {'id': '69332',\n",
       "              'metadata': {'text': ' What is the biggest city?'},\n",
       "              'score': 0.727139473,\n",
       "              'values': []},\n",
       "             {'id': '84749',\n",
       "              'metadata': {'text': \" What are the world's most advanced \"\n",
       "                                   'cities?'},\n",
       "              'score': 0.709211469,\n",
       "              'values': []},\n",
       "             {'id': '109231',\n",
       "              'metadata': {'text': ' Where is the most beautiful city in the '\n",
       "                                   'world?'},\n",
       "              'score': 0.696054876,\n",
       "              'values': []},\n",
       "             {'id': '109230',\n",
       "              'metadata': {'text': ' What is the greatest, most beautiful city '\n",
       "                                   'in the world?'},\n",
       "              'score': 0.657444537,\n",
       "              'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"which city has the highest population in the world?\"\n",
    "\n",
    "# create the query vector\n",
    "xq = model.encode(query).tolist()\n",
    "\n",
    "# now query\n",
    "xc = index.query(vector=xq, top_k=5, include_metadata=True)\n",
    "xc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XwOWcgo_QtI"
   },
   "source": [
    "In the returned response `xc` we can see the most relevant questions to our particular query — we don't have any exact matches but we can see that the returned questions are similar in the topics they are asking about. We can reformat this response to be a little easier to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gy7isg_f-vWg",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79:  What's the world's largest city?\n",
      "0.73:  What is the biggest city?\n",
      "0.71:  What are the world's most advanced cities?\n",
      "0.7:  Where is the most beautiful city in the world?\n",
      "0.66:  What is the greatest, most beautiful city in the world?\n"
     ]
    }
   ],
   "source": [
    "for result in xc['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JK5yApl_5fE"
   },
   "source": [
    "These are good results, let's try and modify the words being used to see if we still surface similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dJbjE-iq_yMr",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64:  What is the biggest city?\n",
      "0.6:  What is the most dangerous city in USA?\n",
      "0.59:  What's the world's largest city?\n",
      "0.59:  What is the most dangerous city in USA? Why?\n",
      "0.58:  What are the world's most advanced cities?\n"
     ]
    }
   ],
   "source": [
    "query = \"which metropolis has the highest number of people?\"\n",
    "\n",
    "# create the query vector\n",
    "xq = model.encode(query).tolist()\n",
    "\n",
    "# now query\n",
    "xc = index.query(vector=xq, top_k=5, include_metadata=True)\n",
    "for result in xc['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIAxOPb-A2w_"
   },
   "source": [
    "Here we used different terms in our query than that of the returned documents. We substituted **\"city\"** for **\"metropolis\"** and **\"populated\"** for **\"number of people\"**.\n",
    "\n",
    "Despite these very different terms and *lack* of term overlap between query and returned documents — we get highly relevant results — this is the power of *semantic search*.\n",
    "\n",
    "## Task 1\n",
    "\n",
    "Try changing the model and querying again. You can find alternative models [here](https://sbert.net/docs/pretrained_models.html). Note that you will need to choose one with the same dimensionality (384). Clicking on the \"info\" symbol next to the model names will tell you information including their dimensionality.\n",
    "\n",
    "Find a model that gives similar results and a model that gives different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-cWdeKzhAtww",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.2.2. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "PineconeApiException",
     "evalue": "(400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Wed, 08 May 2024 09:20:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '103', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '77', 'x-pinecone-request-id': '9214146512602533125', 'x-envoy-upstream-service-time': '78', 'server': 'envoy'})\nHTTP response body: {\"code\":3,\"message\":\"Vector dimension 384 does not match the dimension of the index 1536\",\"details\":[]}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPineconeApiException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_105/1528678045.py\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# now query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mxc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mxc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxq2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mxc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxq3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/utils/error_handling.py\u001b[0m in \u001b[0;36minner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/data/index.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, top_k, vector, id, namespace, filter, include_values, include_metadata, sparse_vector, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m             ]\n\u001b[1;32m    401\u001b[0m         )\n\u001b[0;32m--> 402\u001b[0;31m         response = self._vector_api.query(\n\u001b[0m\u001b[1;32m    403\u001b[0m             QueryRequest(\n\u001b[1;32m    404\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0margs_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \"\"\"\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api/data_plane_api.py\u001b[0m in \u001b[0;36m__query\u001b[0;34m(self, query_request, **kwargs)\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query_request'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 \u001b[0mquery_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         self.query = _Endpoint(\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mcall_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'header'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content-Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         return self.api_client.call_api(\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'endpoint_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'http_method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             return self.__call_api(resource_path, method,\n\u001b[0m\u001b[1;32m    410\u001b[0m                                    \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                                    \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPineconeApiException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# perform request and return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             response_data = self.request(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mpost_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    453\u001b[0m                                             body=body)\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             return self.rest_client.POST(url,\n\u001b[0m\u001b[1;32m    456\u001b[0m                                          \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                                          \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/rest.py\u001b[0m in \u001b[0;36mPOST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m     def POST(self, url, headers=None, query_params=None, post_params=None,\n\u001b[1;32m    301\u001b[0m              body=None, _preload_content=True, _request_timeout=None):\n\u001b[0;32m--> 302\u001b[0;31m         return self.request(\"POST\", url,\n\u001b[0m\u001b[1;32m    303\u001b[0m                             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pinecone/core/client/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mServiceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPineconeApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPineconeApiException\u001b[0m: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Wed, 08 May 2024 09:20:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '103', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '77', 'x-pinecone-request-id': '9214146512602533125', 'x-envoy-upstream-service-time': '78', 'server': 'envoy'})\nHTTP response body: {\"code\":3,\"message\":\"Vector dimension 384 does not match the dimension of the index 1536\",\"details\":[]}\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "model1 = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2', device=device)\n",
    "model2 = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1', device=device)\n",
    "model3= SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', device=device)\n",
    "##showing werror\n",
    "model4= SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L3-v2', device=device)\n",
    "model5= SentenceTransformer('sentence-transformers/all-MiniLM-L12-v1', device=device) \n",
    "model6= SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-dot-v1', device=device) \n",
    "model7= SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L12-v2', device=device)\n",
    "\n",
    "query = \"which city has the highest population in the world?\"\n",
    "\n",
    "xq1 = model1.encode(query).tolist()\n",
    "xq2 = model2.encode(query).tolist()\n",
    "xq3 = model3.encode(query).tolist()\n",
    "xq4 = model4.encode(query).tolist()\n",
    "xq5 = model5.encode(query).tolist()\n",
    "xq6 = model6.encode(query).tolist()\n",
    "xq7 = model7.encode(query).tolist()\n",
    "\n",
    "# now query\n",
    "xc1 = index.query(vector=xq1, top_k=5, include_metadata=True)\n",
    "xc2 = index.query(vector=xq2, top_k=5, include_metadata=True)\n",
    "xc3 = index.query(vector=xq3, top_k=5, include_metadata=True)\n",
    "xc4 = index.query(vector=xq4, top_k=5, include_metadata=True)\n",
    "xc5 = index.query(vector=xq5, top_k=5, include_metadata=True)\n",
    "xc6 = index.query(vector=xq6, top_k=5, include_metadata=True)\n",
    "xc7 = index.query(vector=xq7, top_k=5, include_metadata=True)\n",
    "\n",
    "for result in xc1['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")\n",
    "\n",
    "for result in xc2['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")\n",
    "    \n",
    "for result in xc3['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")\n",
    "    \n",
    "for result in xc4['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")\n",
    "    \n",
    "for result in xc5['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")\n",
    "    \n",
    "for result in xc6['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")\n",
    "\n",
    "for result in xc7['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1oqGm36J94S"
   },
   "source": [
    "# Retrieval Enhanced Generative Question Answering\n",
    "\n",
    "Next, we will see how these queries can be used with an LLM to generate better outputs.\n",
    "\n",
    "We will again use data that has already been prepared (for details, see [this notebook](https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/gen-qa-openai.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nX_fy-BrJ-t1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>sparse_values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35Pdoyi6ZoQ-t0.0</td>\n",
       "      <td>[-0.010402066633105278, -0.018359748646616936,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35Pdoyi6ZoQ-t18.48</td>\n",
       "      <td>[-0.011849376372992992, 0.0007984379190020263,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35Pdoyi6ZoQ-t32.36</td>\n",
       "      <td>[-0.014534404501318932, -0.0003158661129418760...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35Pdoyi6ZoQ-t51.519999999999996</td>\n",
       "      <td>[-0.011597747914493084, -0.007550035137683153,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35Pdoyi6ZoQ-t67.28</td>\n",
       "      <td>[-0.015879768878221512, 0.0030445053707808256,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "0                 35Pdoyi6ZoQ-t0.0   \n",
       "1               35Pdoyi6ZoQ-t18.48   \n",
       "2               35Pdoyi6ZoQ-t32.36   \n",
       "3  35Pdoyi6ZoQ-t51.519999999999996   \n",
       "4               35Pdoyi6ZoQ-t67.28   \n",
       "\n",
       "                                              values sparse_values  \\\n",
       "0  [-0.010402066633105278, -0.018359748646616936,...          None   \n",
       "1  [-0.011849376372992992, 0.0007984379190020263,...          None   \n",
       "2  [-0.014534404501318932, -0.0003158661129418760...          None   \n",
       "3  [-0.011597747914493084, -0.007550035137683153,...          None   \n",
       "4  [-0.015879768878221512, 0.0030445053707808256,...          None   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...  \n",
       "1  {'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...  \n",
       "2  {'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...  \n",
       "3  {'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...  \n",
       "4  {'channel_id': 'UCv83tO5cePwHMt1952IVVHw', 'en...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('youtube-transcripts-text-embedding-ada-002')\n",
    "\n",
    "# we drop sparse_values as they are not needed for this example\n",
    "dataset.documents.drop(['metadata'], axis=1, inplace=True)\n",
    "dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
    "\n",
    "# Print a sample of the data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4KY86YXKBmA"
   },
   "source": [
    "Again, we will set up a pinecone database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7cVhu-tGKJGH",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 38950}},\n",
       " 'total_vector_count': 38950}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'gen-qa-openai-fast'\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,  # dimensionality of text-embedding-ada-002\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liE7x3RiKLXP"
   },
   "source": [
    "As in the previous section, we'll insert the data into the database (this can take 5-10 minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8Mrp_cGJKMfB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in dataset.iter_documents(batch_size=100):\n",
    "    index.upsert(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H356HGpnKM3P"
   },
   "source": [
    "Now we've added all of our langchain docs to the index. With that we can move on to retrieval and then answer generation.\n",
    "\n",
    "## Retrieval\n",
    "\n",
    "To search through our documents we first need to create a query vector `xq`. Using `xq` we will retrieve the most relevant chunks from the LangChain docs. To create that query vector we must initialize a `text-embedding-ada-002` embedding model with OpenAI. For this, you need an [OpenAI API key](https://platform.openai.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "o9m3xdRXKRqA"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BKqh91UyKT4D"
   },
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_105/3833002645.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m res = openai.Embedding.create(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/api_resources/embedding.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# If a user specifies base64, we'll just return the encoded string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             return (\n\u001b[0;32m--> 624\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    625\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    688\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"Which training method should I use for sentence transformers when \" +\n",
    "    \"I only have pairs of related sentences?\"\n",
    ")\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(vector=xq, top_k=2, include_metadata=True)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA7wEDhnKWim"
   },
   "source": [
    "We write some functions to handle the retrieval and completion steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlwUDNbBKXh2"
   },
   "outputs": [],
   "source": [
    "limit = 3750\n",
    "\n",
    "import time\n",
    "\n",
    "def retrieve(query):\n",
    "    res = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        engine=embed_model\n",
    "    )\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    xq = res['data'][0]['embedding']\n",
    "\n",
    "    # get relevant contexts\n",
    "    contexts = []\n",
    "    time_waited = 0\n",
    "    while (len(contexts) < 3 and time_waited < 60 * 12):\n",
    "        res = index.query(vector=xq, top_k=3, include_metadata=True)\n",
    "        contexts = contexts + [\n",
    "            x['metadata']['text'] for x in res['matches']\n",
    "        ]\n",
    "        print(f\"Retrieved {len(contexts)} contexts, sleeping for 15 seconds...\")\n",
    "        time.sleep(15)\n",
    "        time_waited += 15\n",
    "\n",
    "    if time_waited >= 60 * 12:\n",
    "        print(\"Timed out waiting for contexts to be retrieved.\")\n",
    "        contexts = [\"No contexts retrieved. Try to answer the question yourself!\"]\n",
    "\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def complete(prompt):\n",
    "    # instructions\n",
    "    sys_prompt = \"You are a helpful assistant that always answers questions.\"\n",
    "    # query text-davinci-003\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo-0613',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return res['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZgLxE_FKY3L"
   },
   "outputs": [],
   "source": [
    "# first we retrieve relevant items from Pinecone\n",
    "query_with_contexts = retrieve(query)\n",
    "query_with_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Qjw1q7-KaW-"
   },
   "outputs": [],
   "source": [
    "# then we complete the context-infused query\n",
    "complete(query_with_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q91Wd5GNKb_A"
   },
   "source": [
    "And we get a pretty great answer straight away, specifying to use _multiple-rankings loss_ (also called _multiple negatives ranking loss_).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3J4bw3JKgUp"
   },
   "source": [
    "## Task 2 [Optional]\n",
    "\n",
    "Try adjusting the number of contexts down to 1, to see the impact on retrieval quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPSUDTWJKgkX"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y82uI1BDKg4N"
   },
   "source": [
    "## Pack up\n",
    "\n",
    "Once you're done with the lab, delete the indices to save resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iw8DMgvyKe33"
   },
   "outputs": [],
   "source": [
    "pc.delete_index('gen-qa-openai-fast')\n",
    "pc.delete_index('semantic-search-fast')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
